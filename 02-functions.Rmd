# Functions


<p style = "margin-bottom: 0px; font-size: 20px; ">**Functions**</p>


- **Functions**
  - **Concepts**
    - A function is a set of ordered one-to-one or many-to-one pairs of points (based on Spivak)
    - In a function, a number $f(x)$ is determined for each number $x$ in its domain
    - A function can be thought as a rule for a one-to-one or many-to-one mapping of an input into an output (in other words, for relating a set of input to a set of output)
    - It is useful to know that there is no best way of defining a function
    - **Domain** - The domain of a function is the set of input for which a unique output exist for every point in the set of input 
    - **Range** - The codomain or range of a function is the set of output that a function can produce
  - **Related concepts (brief)**
    - **Root of a function** - The root of a function is the point in the domain (or one of the domains in the multivariable case) of the function when the codomain is 0
    - **Intercept of a function** - The intercept of a function is the point in the codomain of the function when the domain is 0
    - **Inverse of a function** - A function that undoes the operation of a function of interest - Mapping the output into the input 
    - **Extremum of a function** - The most extreme point in the codomain of the function
    - **Composition of multiple functions** - A function that is made up by several functions through basic operations (e.g. sum, product, quotient)
    - **Ordered pairs** - Pairs where the order of elements in them matters - E.g. if (a, b) = (c, d), then a = c and b = d. An ordered pair $(a, b)$ is defined as $\{\{a\}, \{a, b\}\}$
    

- **The Limit of a function**
  - **Introduction**
    - The notion of the limit of a function is the foundation of calculus (e.g. functions, continuity, differentiation, integration etc.)
  - **Conceptual definition**
    - The limit ($l$) of a function ($f$) as the input ($x$) of the function approaches/tends towards/is near $a$ is a single value (if any) that the function approaches/tends towards/becomes closer to from either side when the input of the function approaches/tends towards/become closer to $a$ from either side, but not $a$
    - That means the limit of a function near $a$ exists only when the function does in fact approach towards the limit $l$ (i.e. a single value) when the input approaches towards $a$. However, when the function does not approach towards the limit $l$ when the input approaches towards $a$, then the limit of the function near $a$ does not exist 
    - The notion of a function approaching a limit describes the value of the input of the function as approaching a certain value from either side as the value of the output of the function approaches the limit from either side of it 
    - In other words, it describes the value that the input needs to be close to or approach to in order to get a value of the output of the function close to or approaches the limit 
  - **Mathematical expression**
    - **Expression 1 (Hardy)**
      - $\displaystyle \lim_{x \rightarrow a} f(x) = l$
        - ***Notes***
          - It reads "The limit of the function $f(x)$ as $x$ approaches $a$ is $l$"
    - **Expression 2**
      - $f(x) \rightarrow l ~~~~~\text{as} ~~~~~ x \rightarrow a$
        - ***Notes**
          - It reads "$f(x)$ approaches $l$ as $x$ approaches $a$
  - **Precise definition**
    - The function $f$ approaches the limit $l$ near $a$ is defined as the closeness around $a$ for any given closeness around $l$ with closeness defined as intervals around $l$ and $a$- Specifically, an interval around the limit of any given distance $\varepsilon$ between the limit and either of its boundaries always has a corresponding interval around $a$ with a certain distance $\delta$ between $a$ and either of its boundaries such that any values within the interval around $a$ is mapped by the function into values that is guaranteed to be within the aforementioned interval around the limit
  - **Mathematics**
    - For every $\epsilon > 0$ there is some $\delta > 0$ such that, for all $x$, if $0 < |x - a| < \delta$, then it implies $|f(x) - l| < \varepsilon$ 
  - **Theories**
    - **Theorem 1**
      - **Concept**
        - A function $f$ can only have one limit $l$ near $a$
    - **The 3 Properties of Limits**
      - **Concept**
        - If $x$ is close to $x_0$ and $y$ is close to $y_0$, then $x + y$ is close to $x_0 + y_0$, and $xy$ is close to $x_0y_0$, and $\frac{1}{y}$ is close to $\frac{1}{y_0}$ 
      - **The sum law of limits**
        - **Mathematics**
          - If 
            - $\lim_{x \rightarrow a} f(x) = L$ and $\lim_{x \rightarrow a} g(x) = M$
          - Then 
            - $\displaystyle \lim_{x \rightarrow a}(f ± g)(x) = \lim_{x \rightarrow a} f(x) ± \lim_{x \rightarrow a}g(x) = L ± M$ 
        - <details><summary>**Proof**</summary>
          - Given that 
            - $\displaystyle \lim_{x \rightarrow a} = L \\ ~~~~~ \forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) - L| < \epsilon \\ \displaystyle \lim_{x \rightarrow a} = M \\ ~~~~~ \forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |g(x) - M| < \epsilon$
          - We are trying to prove:
            - $\displaystyle \lim_{x \rightarrow a}(f + g)(x) = L + M\\ ~~~~~  \forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) + g(x) - L - M| < \epsilon$
          - We can rearrange the last bit as 
            - $\forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) - L + g(x) - M| < \epsilon$
          - So that we can use the Triangle Inequality to separate the last term as 
            - $\forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) - l + g(x) - M| ≤ |f(x) - L| + |g(x) - M| < \epsilon$
          - We need to make this statement work by adjusting the $\epsilon$ and $\delta$: 
            - $\displaystyle \lim_{x \rightarrow a} = L \\ ~~~~~ \forall \epsilon > 0, \exists \delta_1 > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta_1 \implies 0 < |f(x) - L| < \frac{\epsilon}{2} \\ \displaystyle \lim_{x \rightarrow a} = M \\ ~~~~~ \forall \epsilon > 0, \exists \delta_2 > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta_2 \implies 0 < |g(x) - M| < \frac{\epsilon}{2}$
              - ***Note***
                - Now we adjust the $\epsilon$ to $\frac{\epsilon}{2}$, so that when they are added up, they are equal to $\epsilon$. Reducing $\epsilon$ to $\frac{\epsilon}{2}$ may also reduce the corresponding $\delta_1$, which is for $\lim_{x \rightarrow a}f(x)$, and $delta_2$, which is for $\lim_{x \rightarrow a}g(x)$ 
          - Now back to this thing: 
            - $\forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) - l + g(x) - M| ≤ |f(x) - L| + |g(x) - M| < \epsilon$
          - Let $\delta$ in this thing be $\min(\delta_1, \delta_2)$ (because the smaller $\delta$ will ensure that it will work for both $\lim_{x \rightarrow a}f(x)$ and $\lim_{x \rightarrow a}g(x)$ in that thing)
          - Consequently: 
            - $\forall \epsilon > 0, \exists \delta = \min(\delta_1, \delta_2) > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) - l + g(x) - M| ≤ |f(x) - L| + |g(x) - M| < \frac{\epsilon}{2} + \frac{\epsilon}{2} < \epsilon \blacksquare$ 
            </details>
            
        - **The multiplicative law of limits**
          - **Mathematics**
            - If 
              - $\lim_{x \rightarrow a} f(x) = L$ and $\lim_{x \rightarrow a} g(x) = M$
            - Then
              - $\displaystyle \lim_{x \rightarrow a}(f \times g)(x) = \lim_{x \rightarrow a} f(x) \times \lim_{x \rightarrow a}g(x) = L M$
          - <details><summary>**Proof**</summary>
            - We are trying to prove:
              - $\displaystyle \lim_{x \rightarrow a}(f g)(x) = LM\\ ~~~~~  \forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) g(x) - L M| < \epsilon$
            - We can manipulate the last bit as
              - $\forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x) g(x) - f(x) M + f(x) M - L M| < \epsilon$
            - So that we can separate out the last term as 
              - $\forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x)| |g(x) - M| + |M| |f(x) - L| < \epsilon$
            - We need to make the statement work by requiring each of the last two terms to be less than half of $\epsilon$:
              - $\displaystyle \begin{aligned} |f(x)| |g(x) - M| &< \frac{\epsilon}{2} \\ |M| |f(x) - L| &< \frac{\epsilon}{2}\end{aligned}$
            - We have to find a $\delta$ that make both statements work
              - Find a $\delta$ that works for the second term 
                - To make 
                  - $\displaystyle |M| |f(x) - L| < \frac{\epsilon}{2}$
                - We can make 
                  - $\displaystyle |f(x) - L| < \frac{\epsilon}{2 |M|}$
                - However, there is a possibility that $|M| < 1$, which would not ensure $\displaystyle |M| |f(x) - L| < \frac{\epsilon}{2}$
                - Hence, we add one to the denominator to ensure that the denominator is always $≥ 2$:
                  - $\displaystyle |f(x) - L| < \frac{\epsilon}{2 \left[ |M| + 1\right]}$
                - Consequently, the $\delta$ to meet this condition is $\delta_2$
                  - $\displaystyle \lim_{x \rightarrow a}f(x) = L \\ \displaystyle ~~~~~ \forall \epsilon > 0, \exists \delta_2 > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta_1 \implies 0 < |f(x) - L| < \frac{\epsilon}{2 \left[ |M| + 1\right]}$
              - Find a $\delta$ that works for the first term
                - To make
                  - $\displaystyle |f(x)| |g(x) - M| < \frac{\epsilon}{2}$
                - We can make
                  - $\displaystyle  |g(x) - M| < \frac{\epsilon}{2 |f(x)|}$
                - But we also need to turn $|f(x)|$ into a constant so that it can be worked with
                  - We know that 
                    - $\begin{aligned} \displaystyle |f(x) - L| &< \frac{\epsilon}{2 \left[ |M| + 1\right]} \\ \displaystyle |f(x)| &< |L| + \frac{\epsilon}{2 \left[ |M| + 1\right]} \end{aligned}$
                  - Hence, we can write it as
                    - $\displaystyle  |g(x) - M| < \frac{\epsilon}{2 |L| + \frac{\epsilon}{2 \left[ |M| + 1\right]}}$
                      - Note that because $|f(x)| < |L| + \frac{\epsilon}{2 \left[ |M| + 1\right]}$, $\frac{\epsilon}{2 |L| + \frac{\epsilon}{2 \left[ |M| + 1\right]}}$ is even smaller (and more conservative) than $\displaystyle \frac{\epsilon}{2 |f(x)|}$
                  - Consequently, the $\delta$ satisfies this condition is $\delta_1$ such that:
                    - $\displaystyle \lim_{x \rightarrow a} g(x) = M \\ \displaystyle ~~~~~ \forall \epsilon > 0, \exists \delta_1 > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta_1 \implies 0 < |g(x) - L| < \frac{\epsilon}{2 |L| + \frac{\epsilon}{2 \left[ |M| + 1\right]}}$
              - Now that we have 2 $\delta$s, we have to choose one that works for both case. Of course, the smaller one would ensure it works for both cases:
                - Let $\delta = \min(\delta_1, \delta_2)$
            - Now we have the a $\delta$ so that:
              - $\displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |f(x)| |g(x) - M| + |M| |f(x) - L| < \epsilon \\ \displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \left( |L| + \frac{\epsilon}{2 \left[ |M| + 1\right]}\right)\frac{\epsilon}{2 |L| + \frac{\epsilon}{2 \left[ |M| + 1\right]}}+ |M| \frac{\epsilon}{2 \left[ |M| + 1\right]}< \epsilon \\ \displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{s.t}, \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{\epsilon}{2} + \frac{\epsilon}{2} < \epsilon ~~~ \blacksquare$ 
            </details>
            
        - **The inverse law of limits**
          - **Mathematics**
            - Given that
              - $\displaystyle \lim_{x \rightarrow a} g(x) = M \\ \text{using the} ~ \epsilon - \delta ~ \text{definition of limits, that is:} \\ \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |g(x) - M| < \epsilon$
            - Then
              - $\displaystyle \lim_{x \rightarrow a}\left(\frac{1}{g}\right)(x) = \frac{1}{\lim_{x \rightarrow a}g(x)} = \frac{1}{M} ~~~~~\text{if}~ M ≠ 0 \\  \text{using the} ~ \epsilon - \delta ~ \text{definition of limits, that is:} \\ \displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \left|\frac{1}{g(x)} - \frac{1}{M}\right| < \epsilon$
          - **Proof**
            - Given that
              - $\displaystyle \lim_{x \rightarrow a} g(x) = M \\ \text{using the} ~ \epsilon - \delta ~ \text{definition of limits, that is:} \\ \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |g(x) - M| < \epsilon ~~~~~ (1)$
            - Proof that
              - $\displaystyle \lim_{x \rightarrow a}\left(\frac{1}{g}\right)(x) = \frac{1}{\lim_{x \rightarrow a}g(x)} = \frac{1}{M} ~~~~~\text{if}~ M ≠ 0 \\  \text{using the} ~ \epsilon - \delta ~ \text{definition of limits, that is:} \\ \displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \left|\frac{1}{g(x)} - \frac{1}{M}\right| < \epsilon \\ \text{We can express this in a way that helps us prove it:}\\ \displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{|g(x) - M|}{|g(x)| |M|} < \epsilon \\ \displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{|g(x) - M|}{|M|}\frac{1}{|g(x)|} < \epsilon ~~~~~ (2)$
            - We can first work with this $\frac{1}{|g(x)|}$ part of $(2)$ through equation $(1)$
              - Let's remind ourselves what $(1)$ is:
                - $\forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |g(x) - M| < \epsilon ~~~~~ (1)$
              - Consider letting $\epsilon = \frac{|M|}{2}$, then:
                - $\exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |g(x) - M| < \frac{|M|}{2}$
                  - ***Notes***
                    - We are letting $\epsilon = \frac{|M|}{2}$ because $\epsilon$ can be any arbitrary real number AND this value helps us prove $(2)$
              - We can manipulate the last bit to make it look like $(2)$:
                - First starting with:
                  - $\epsilon = \frac{|M|}{2}, \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |g(x) - M| < \frac{|M|}{2}$
                - We can switch between $g(x)$ and $M$:
                  - $\epsilon = \frac{|M|}{2}, \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |M - g(x)| < \frac{|M|}{2}$
                - We can add $|g(x)|$ to both sides:
                  - $\epsilon = \frac{|M|}{2},  \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |M - g(x)| + |g(x)| < \frac{|M|}{2} + |g(x)|$
                - We can then reverse the Triangle Inequality to get:
                  - $\displaystyle \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |M - g(x) + g(x)| ≤ |g(x) - M| + |g(x)| < \frac{|M|}{2} + |g(x)| \\ \displaystyle  \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |M| ≤ |g(x) - M| + |g(x)| < \frac{|M|}{2} + |g(x)|$
                - We can just delete the middle part and get:
                  - $\displaystyle \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |M| < \frac{|M|}{2} + |g(x)| \\ \displaystyle \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |M| - \frac{|M|}{2} < |g(x)| \\ \displaystyle \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{1}{|g(x)|} <  \frac{2}{|M|}$
                - We can multiply both sides of the inequality by $\frac{|g(x) - M|}{|M|}$ (because this quantity is positive, it would not change the sign of the inequality)
                  - $\displaystyle \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta_1 \implies 0 < \frac{|g(x) - M|}{|M|}  \frac{1}{|g(x)|} <  \frac{|g(x) - M|}{|M|} \frac{2}{|M|} \\ \displaystyle \exists \delta_1 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta_1 \implies 0 < \frac{|g(x) - M|}{|M|}  \frac{1}{|g(x)|} <  |g(x) - M| \frac{2}{|M|^2}$
                - Now we need to prove that 
                  - $\displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{|g(x) - M|}{|M|}  \frac{1}{|g(x)|} <  |g(x) - M| \frac{2}{|M|^2} < \epsilon$
                - Since we have proved 
                  - $\displaystyle \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{|g(x) - M|}{|M|}  \frac{1}{|g(x)|} <  |g(x) - M| \frac{2}{|M|^2} $
                - We can focus on proving 
                  - $\displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0  <  |g(x) - M| \frac{2}{|M|^2} < \epsilon$
                - We can use what we know is true
                  - $\displaystyle \lim_{x \rightarrow a} g(x) = M \\ \text{using the} ~ \epsilon - \delta ~ \text{definition of limits, that is:} \\ \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < |g(x) - M| < \epsilon ~~~~~ (1)$
                - We can let $\epsilon = \epsilon \frac{|M|^2}{2}$, then:
                  - $\displaystyle \forall \epsilon > 0, \exists \delta_2 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta_2 \implies 0 < |g(x) - M| < \epsilon  \frac{|M|^2}{2} ~~~~~ (1)$
                - Then if we multiply both sides by $\frac{2}{|M|^2} $, $\delta_2$ would still work and we get what we want in order to prove this shit 
                  - $\displaystyle \forall \epsilon > 0, \exists \delta_2 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta_2 \implies 0 < |g(x) - M|\frac{2}{|M|^2} < \epsilon  \frac{|M|^2}{2}\frac{2}{|M|^2} \\ \displaystyle \forall \epsilon > 0, \exists \delta_2 > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta_2 \implies 0 < |g(x) - M|\frac{2}{|M|^2} < \epsilon  $
                - Now that we have 2 $\delta$s ($\delta_1$ and $\delta_2$), we will select one that ensure both of the above conditions to satisfy, of course, the smaller one would be the one, hence let $\delta = \min(\delta_1, \delta_2)$, then:
                  - $\displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{|g(x) - M|}{|M|}  \frac{1}{|g(x)|} <  |g(x) - M| \frac{2}{|M|^2} < \epsilon \\ \displaystyle \forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \forall x \in \mathbb{R}, 0 < |x - a| < \delta \implies 0 < \frac{|g(x) - M|}{|M|}  \frac{1}{|g(x)|} < \epsilon ~~~~~ \blacksquare$
    
        - **The constant law of limits**
          - **Mathematics**
            - $\lim_{x \rightarrow a}c = c$
  


    
    
 Some concepts    
      - **Concept**
    - The most extreme value of the output of a function (plural is extrema)
  - **Types of Extremum**
    - **Maximum vs Minimum**
      - **Maximum** 
        - The highest possible value of the output of a function 
      - **Minimum** 
        - The smallest possible value of the output of a function
    - **Global vs Local**
      - **Local extrema** 
        - The extrema of the function within a certain range of the domain (the variables)
      - **Global extrema** 
        - The extrema of the function on the entire domain of the function 